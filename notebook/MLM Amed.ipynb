{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463dae00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:09.725909Z",
     "start_time": "2022-07-31T09:18:09.712003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Desktop/Kaggle/Script/NLP/FPrize Effective Arguments/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6c4be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:12.241816Z",
     "start_time": "2022-07-31T09:18:10.288494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# from utils.viz import visualize\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM = true\n",
    "\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 500)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52dec2e",
   "metadata": {},
   "source": [
    "test/ - A folder containing an example essay from the test set. The actual test set comprises about 3,000 essays in a format similar to the training set essays.\n",
    "The test set essays are distinct from the training set essays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1ce74",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2284d8d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:12.245498Z",
     "start_time": "2022-07-31T09:18:12.243371Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DATA = Path('../data/')\n",
    "data_folder = ROOT_DATA/\"feedback-prize-effectiveness\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807dfc34",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bd28761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:12.367952Z",
     "start_time": "2022-07-31T09:18:12.246739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144293, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(ROOT_DATA/'feedback-prize-2021'/\"train.csv\")\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4496d362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end                                     discourse_text discourse_type discourse_type_num                                   predictionstring\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0  Modern humans today are always on their phone....           Lead             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0  They are some really bad consequences when stu...       Position         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e488d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['essay_id'] = train_df['id'] if \"essay_id\" not in train_df.columns else train_df['essay_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90103b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:12.948457Z",
     "start_time": "2022-07-31T09:18:12.927332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4191, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_df = pd.read_csv(data_folder/\"df_folds.csv\")\n",
    "fold_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c499694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:13.409635Z",
     "start_time": "2022-07-31T09:18:13.392942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>fold_k_5_seed_42</th>\n",
       "      <th>fold_k_5_seed_2020</th>\n",
       "      <th>fold_k_8_seed_42</th>\n",
       "      <th>fold_k_8_seed_2020</th>\n",
       "      <th>fold_k_10_seed_42</th>\n",
       "      <th>fold_k_10_seed_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  fold_k_5_seed_42  fold_k_5_seed_2020  fold_k_8_seed_42  fold_k_8_seed_2020  fold_k_10_seed_42  fold_k_10_seed_2020\n",
       "0  00066EA9880D                 2                   3                 0                   6                  4                    8\n",
       "1  000E6DE9E817                 2                   1                 5                   3                  4                    9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f8632a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:13.840315Z",
     "start_time": "2022-07-31T09:18:13.814864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144293, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(fold_df,how='left',on=\"essay_id\")\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c1c023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:14.353420Z",
     "start_time": "2022-07-31T09:18:14.338502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>fold_k_5_seed_42</th>\n",
       "      <th>fold_k_5_seed_2020</th>\n",
       "      <th>fold_k_8_seed_42</th>\n",
       "      <th>fold_k_8_seed_2020</th>\n",
       "      <th>fold_k_10_seed_42</th>\n",
       "      <th>fold_k_10_seed_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end                                     discourse_text discourse_type discourse_type_num                                   predictionstring      essay_id  fold_k_5_seed_42  fold_k_5_seed_2020  fold_k_8_seed_42  fold_k_8_seed_2020  fold_k_10_seed_42  fold_k_10_seed_2020\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0  Modern humans today are always on their phone....           Lead             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  423A1CA112E2               4.0                 2.0               5.0                 4.0                8.0                  8.0\n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0  They are some really bad consequences when stu...       Position         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  423A1CA112E2               4.0                 2.0               5.0                 4.0                8.0                  8.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e85a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['fold_k_5_seed_42']:\n",
    "    train_df[c] = train_df[c].fillna(20).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec11885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    107528\n",
       "4       7441\n",
       "0       7381\n",
       "1       7343\n",
       "2       7324\n",
       "3       7276\n",
       "Name: fold_k_5_seed_42, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[c].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f49cfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df[c]!=20,c] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76598032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:14.923086Z",
     "start_time": "2022-07-31T09:18:14.903555Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.discourse_effectiveness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97df8da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:15.366793Z",
     "start_time": "2022-07-31T09:18:15.361129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ineffective': 0, 'Adequate': 1, 'Effective': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_mapper = {'Ineffective':0,\"Adequate\":1,\"Effective\":2}\n",
    "classe_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6532ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:15.789632Z",
     "start_time": "2022-07-31T09:18:15.778906Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df['target'] = train_df['discourse_effectiveness'].map(classe_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa800af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['target'] = 1 if \"discourse_effectiveness\" not in train_df.columns else train_df['discourse_effectiveness'].map(classe_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adcb6e76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:16.254962Z",
     "start_time": "2022-07-31T09:18:16.247016Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10effb7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:16.773094Z",
     "start_time": "2022-07-31T09:18:16.686826Z"
    }
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    seed = 2022\n",
    "    \n",
    "    # Model\n",
    "    model_name = \"microsoft/deberta-v3-large\" #\"funnel-transformer/large\" #\"allenai/longformer-large-4096\"\n",
    "    \n",
    "    # CV\n",
    "    kfold_name = \"fold_k_5_seed_42\"\n",
    "    selected_folds = [0,1,2,3,4]\n",
    "    \n",
    "    # Paths\n",
    "    data_folder = ROOT_DATA/'feedback-prize-2021'\n",
    "    name = \"deberta_v3_large\"\n",
    "    checkpoints_path = Path(fr'../checkpoint/MLM/{name}/')\n",
    "    pretrained_path = Path(fr'../checkpoint/MLM/{name}/glob/')\n",
    "    add_special_tokens = True\n",
    "    input_type = \"cls_end\"\n",
    "    sample = False\n",
    "    mask_pct = 0.15\n",
    "    use_dropout = True\n",
    "    use_gradient_checkpointing = True\n",
    "    # Names\n",
    "    checkpoints_name = 'log'   \n",
    "    \n",
    "    model = {\n",
    "            \"max_len\":1024,\n",
    "            'loss':\"nn.CrossEntropyLoss\",\n",
    "            'pretrained_config':Path(fr'../checkpoint/MLM/{name}/config.pth'),\n",
    "            \"pretrained_weights\":None,\n",
    "            \"pretrained_tokenizer\":Path(fr'../checkpoint/MLM/{name}/tokenizer'),\n",
    "            \"num_labels\":3,\n",
    "            \"model_name\":model_name\n",
    "            }\n",
    "    \n",
    "    optimizer = {\n",
    "            \"name\":\"optim.AdamW\",\n",
    "            'params':{\"lr\":4e-6,'eps':1e-6,\"betas\":[0.9, 0.999],\n",
    "                     \"weight_decay\": 0.01\n",
    "                     },            \n",
    "            }\n",
    "\n",
    "    scheduler = {\n",
    "            \"name\":\"poly\",\n",
    "            'params':{\n",
    "                      \"lr_end\":1e-7,\"power\":3,\"epochs\":10\n",
    "                     },\n",
    "            \"warmup\":0.1,            \n",
    "            }\n",
    "    \n",
    "    train_loader = {\n",
    "            \"batch_size\":1,\n",
    "            'drop_last':True,\n",
    "            \"num_workers\":15,\n",
    "            \"pin_memory\":False,\n",
    "            \"shuffle\":True,\n",
    "            }\n",
    "    \n",
    "    val_loader = {\n",
    "            \"batch_size\":1,\n",
    "            'drop_last':False,\n",
    "            \"num_workers\":15,\n",
    "            \"pin_memory\":False,\n",
    "            \"shuffle\":False\n",
    "            }\n",
    "    trainer = {\"use_amp\":False,'epochs':10}\n",
    "    callbacks = {'save':True,\"es\":False,\"patience\":0,\n",
    "                 'verbose_eval':1,\"epoch_pct_eval\":5/5,\"epoch_eval_dist\":\"uniforme\",\n",
    "                 \"metric_track\":\"val_loss\",\"mode\":\"min\",'top_k':1,\"softmax_before\":0\n",
    "                }\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     device = torch.device(\"cpu\")\n",
    "    \n",
    "args.checkpoints_path.mkdir(parents=True,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b44bff0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T09:18:17.787929Z",
     "start_time": "2022-07-31T09:18:17.582814Z"
    }
   },
   "outputs": [],
   "source": [
    "from train_utils_mlm import kfold,FeedbackModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bddd7a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T10:09:53.140449Z",
     "start_time": "2022-07-31T09:18:18.377058Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- fold_k_5_seed_42 ---------\n",
      "\n",
      "-------------   Fold 1 / 6  -------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1da327d158e458f8a363eab63631371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3484b0521f5942f39cf7ae3a4789e387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012060042aa84d86803fcc57dacc1d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/838 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bb14846e734542a79b6d28c692e140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/838 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pretrained Weights\n",
      "../checkpoint/MLM/deberta_v3_large/glob/global_val_log_loss=1.8484 .pth\n",
      "reseizing in nn\n",
      "Using Pretrained Weights\n",
      "../checkpoint/MLM/deberta_v3_large/glob/global_val_log_loss=1.8484 .pth\n",
      "    -> 565142544 trainable parameters\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964cc02305e04746b3a8effbfc8b4f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] ▁The ▁Benefits ▁of [MASK] - Designed ▁Summer ▁Projects \n",
      " [MASK] [MASK] ▁School ▁requires ▁studying , ▁tests , ▁practicing , ▁and ▁now [MASK] ▁what ▁is ▁called ▁a ▁summer ▁project . ▁This ▁means ▁doing ▁something [MASK] [MASK] ▁break [MASK] ▁relates ▁to ▁some ▁sort ▁of ▁school ▁subject . [MASK] [MASK] ▁Students [MASK] ▁be ▁able ▁to ▁design ▁their [MASK] [MASK] [MASK] [MASK] ▁because ▁Kres ▁it ▁is ▁their ▁time ▁off , [MASK] [MASK] [MASK] ▁would ▁have Greater ▁luxury ▁of ▁choosing ▁their ▁own ▁topic , ▁Wore ▁and [MASK] ▁they ▁would [MASK] ▁until ▁importance ▁of ▁constructing ▁and ▁designing ▁their ▁own ▁project . GMP [MASK] ▁Teachers ▁could [MASK] ▁that ▁there ▁are ▁more ▁learning ▁benefits ▁for [MASK] [MASK] ▁if ▁it ▁is ▁teacher - [MASK] , [MASK] [MASK] ▁but ▁at ▁the ▁end ▁of [MASK] ▁day , ▁summer ▁is ▁supposed ▁to [MASK] ▁a ▁time ▁off ▁from ▁instructional ▁learning . [MASK] \n",
      " \n",
      " ▁Summer ▁break ▁is ▁supposed ▁to [MASK] ▁a ▁time ▁for ▁students ▁to ▁relax ▁and ▁reflect ▁on ▁their [MASK] [MASK] [MASK] ▁school [MASK] [MASK] ▁Normally [MASK] ▁have ▁plans ▁over ▁summer , ▁maybe ▁to ▁travel [MASK] ▁visit ▁family , ▁get [MASK] ▁job , ▁etc . ▁If ▁a ▁teacher ▁assigns ▁a ▁project ▁over ▁summer , [MASK] ▁could ▁interfere [MASK] ▁plans ▁already ▁made ; ▁whereas ▁if ▁a ▁student ▁designs [MASK] [MASK] ▁project , ▁they ▁can ▁schedule ▁it ▁to ▁fit ▁their [MASK] . [MASK] [MASK] [MASK] ▁the ▁hard ▁classes ▁kids [MASK] ▁during ▁the ▁school ▁year , ▁cosmological ▁break ▁helps [MASK] [MASK] ▁and ▁prepare ▁for ▁the ▁next ▁year [MASK] ▁A ▁student - designed ▁project [MASK] ▁give ▁kids ▁the ▁benefit ▁to [MASK] [MASK] ▁own ▁rules ▁and ▁set ▁their ▁own ▁limits ▁to ▁what ▁they ▁can ▁handle . [MASK] [MASK] [MASK] ▁A ▁student - [MASK] ▁summer ▁project ▁would [MASK] ▁that ▁the ▁student ▁could ▁pick ▁whatever ▁topic ▁they ▁choose , ▁and ▁carry ▁it ▁out ▁however ▁they ▁choose [MASK] [MASK] [MASK] ▁set ▁guidelines ▁from [MASK] [MASK] ▁can [MASK] ▁in ▁one ' s ▁imagination . ▁Summer ▁is ▁the ▁time [MASK] ▁people ▁to ▁explore [MASK] ▁do [MASK] ▁that ▁interest ▁them , ▁if [MASK] ▁teacher [MASK] ▁out ▁a ▁topic [MASK] ▁each ▁student , ▁it ▁might ▁not ▁be ▁what ▁the ▁students ▁are ▁drawn [MASK] [MASK] ▁their [MASK] [MASK] ▁a ▁great ▁project ▁could ▁slip ▁away . ▁It ▁is [MASK] ▁much ▁easier ▁and ▁more ▁fun ▁to ▁do ▁a ▁project ▁that ▁you ▁are ▁passion iate ▁about , ▁instead ▁of ▁one ▁that ▁you ▁are ▁only ▁doing ▁for ▁a ▁grade . [MASK] \n",
      " \n",
      " ▁Projects ▁can ▁require ▁a ▁lot ▁of ▁planning [MASK] ▁focus , ▁and [MASK] . ▁Student - designed ▁summer ▁projects ▁will ▁teach ▁kids ▁the ▁importance ▁of ▁constructing ▁their ▁own ▁projects ▁and ▁meeting [MASK] ▁on ▁their [MASK] . [MASK] ▁This ▁would ▁give ▁students ▁the ▁chance [MASK] [MASK] ▁their ▁own ▁voice ▁on ▁their ▁project , ▁and ▁it ▁would ▁prepare ▁them [MASK] ▁the ▁real ▁world . ▁Teachers ▁often [MASK] [MASK] ▁rubric s , ▁resources , ▁guidelines , ▁etc . ▁to [MASK] , [MASK] ▁work [MASK] ▁not ▁always ▁just ▁going ▁to ▁be ▁written ▁out ▁step - by - step [MASK] ▁them [MASK] ▁Without [MASK] ▁baby ing ▁of ▁a ▁teacher , ▁students ▁would ▁learn ▁to ▁be ▁confident ▁in ▁their ▁own ▁work [MASK] ▁not ▁second - [MASK] ▁themselves . [end_evidence] \n",
      " \n",
      " supplies ▁One ▁might ▁argue ▁that ▁teacher [MASK] designed ▁summer ▁projects ▁are ▁better ▁for [MASK] [MASK] ▁and ▁skills . ▁Teacher - designed ▁projects ▁would ▁probably ▁be [MASK] ▁little ▁more ▁straight ▁forward ▁and ▁tell ▁the ▁students ▁exactly ▁what [MASK] ▁are ▁looking ▁for [MASK] ▁their ▁projects . ▁They ▁might ▁also ▁benefit ▁students ▁in ▁an ▁area ▁that ▁they [MASK] ▁in ▁before ; ▁the ▁projects [MASK] ▁be ▁focused ▁around ▁one ▁specific ▁subject ▁for ▁each ▁student . ▁Teacher - designed ▁projects ▁would ▁probably ▁be ▁much ▁easier ▁for ▁teachers ▁to ▁grade ▁because ▁they ▁would ▁Tse ▁likely ▁make ▁a ▁rubric ▁and ▁guidelines [MASK] [MASK] ▁projects [MASK] [end_counterclaim] [MASK] ▁All ▁of ▁these [MASK] ▁still ▁do ▁not [MASK] ▁up ▁for ▁the ▁endless ▁opportunities ▁that ▁kids ▁would [MASK] ▁if [MASK] ▁summer ▁projects ▁were ▁student - designed . [end_rebuttal] \n",
      " \n",
      " ▁All ▁character ▁all , [MASK] ▁student [MASK] designed ▁summer [MASK] ▁would [MASK] ▁kids [MASK] ▁more ▁ways [MASK] ▁one ▁expectancies ▁Kids ▁need ▁to 包括 ▁time ▁off ▁from ▁school ▁in ▁the [MASK] , ▁they ▁need ▁to ▁have ▁the ▁luxury ▁of ▁choosing ▁their ▁own ▁topic , ▁and ▁they ▁need ▁to ▁be ▁prepared ▁to ▁construct ▁their ▁own ▁work ▁like ▁they ▁would ▁in ▁the ▁real ▁world . [MASK] ▁the ▁purpose ▁of ▁projects ▁are ▁to ▁learn ▁and ▁understand ▁something ▁better , ▁why ▁not ▁let ▁kids ▁grow [MASK] ▁people ▁while ▁learning ▁school [MASK] [MASK] ▁material ? [MASK] [SEP]\n",
      "Epoch 1.1/10 lr=0.000003 t=6827s   train_loss=3.8627   val_loss=2.3750  val_log_loss=2.3750 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94114d4c69ed41b6a8261a11ffd5cb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2.1/10 lr=0.000002 t=6841s   train_loss=2.3126   val_loss=1.8797  val_log_loss=1.8797 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b038a395154076af7bbc966d13360c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3.1/10 lr=0.000001 t=7086s   train_loss=2.0317   val_loss=1.6720  val_log_loss=1.6720 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dbcdb4ee7240a0ad3a07454ca93cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4.1/10 lr=0.000001 t=5634s   train_loss=1.8809   val_loss=1.5599  val_log_loss=1.5599 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d466330437c245b69ad287396a7b8bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5.1/10 lr=0.000001 t=4634s   train_loss=1.7911   val_loss=1.4987  val_log_loss=1.4987 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ab8be121c441c1a55ae4b8de1a2b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6.1/10 lr=0.000000 t=4638s   train_loss=1.7374   val_loss=1.4647  val_log_loss=1.4647 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7aed4f3e7a46c0841129c5da90145d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7.1/10 lr=0.000000 t=4637s   train_loss=1.7068   val_loss=1.4447  val_log_loss=1.4447 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69688c5f3965433eb23cf09920e80e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8.1/10 lr=0.000000 t=4657s   train_loss=1.6885   val_loss=1.4329  val_log_loss=1.4329 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290f6450971e4bfa8b67c3d7d0fbc50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9.1/10 lr=0.000000 t=4831s   train_loss=1.6779   val_loss=1.4258  val_log_loss=1.4258 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33725b92b1c41aab8b8dc9ac7007f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10.1/10 lr=0.000000 t=5335s   train_loss=1.6708   val_loss=1.4197  val_log_loss=1.4197 \n",
      "\n",
      "-------------   Fold 2 / 6  -------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e89022136b47b892b511cb8c24b5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577c18076f8d47d3bbb73956f3f8afc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f4dfefbca54174833787df40ad47a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a37eb3436bd4e7ebb646849a32f4c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pretrained Weights\n",
      "../checkpoint/MLM/deberta_v3_large/glob/global_val_log_loss=1.8484 .pth\n",
      "reseizing in nn\n",
      "Using Pretrained Weights\n",
      "../checkpoint/MLM/deberta_v3_large/glob/global_val_log_loss=1.8484 .pth\n",
      "    -> 565142544 trainable parameters\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3674e1b2b5184252b0f755b87420b938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MASK] [MASK] ▁Under ▁the ▁elect [MASK] ▁college [MASK] , ▁voters ▁vote ▁not ▁for ▁the [MASK] , [MASK] ▁for ▁a ▁slate ▁of ▁electors , ▁who ▁in [MASK] ▁elect ▁the ▁President . [MASK] [MASK] ▁If ▁the [MASK] ▁are ▁indeed ▁in titled [MASK] ▁their ▁opinion ▁and ▁they ▁a [MASK] ve ▁the ▁power [MASK] ▁come ▁the [MASK] ▁has ▁yet ▁to ▁even [MASK] ▁about ▁changing ▁the ▁elect orial [MASK] ▁process . ▁If [MASK] ▁people ▁do ▁in fact ▁get ▁to [MASK] ▁for ▁which ▁ever ▁President ▁they ▁want , [MASK] [MASK] ▁come [MASK] ksha ▁vote ▁for ▁someone ▁to ▁vote ▁for ▁them , ▁not ▁even ▁considering ▁that ▁that ▁person ▁that ▁they ▁voted ▁for ▁just ▁might ▁defy ▁dork ▁will ▁of ▁the ▁people ▁and ▁choose ▁the ▁other ▁candidate . [MASK] \n",
      " \n",
      " [MASK] ▁The ▁single ▁best ▁argument [MASK] ▁the ▁el ce torial ▁college ▁is ▁what [MASK] ▁might ▁call ▁the ▁disaster ▁factor . [MASK] ▁' ▁vegetables [MASK] [MASK] ▁in ▁1960 ▁segregation [MASK] ▁in ▁the [MASK] ian [MASK] ▁legislature [MASK] ▁succeeded ▁in ▁replacing [MASK] ▁new [MASK] ▁electors ▁with ▁new [MASK] ▁who ▁would ▁oppose ▁John ▁F . ▁Kennedy . ( So ▁Pyongyang ▁Sonoran ▁popular ない ▁to ▁Kennedy ▁would ▁not ▁actually ▁go ▁to ▁Israelite ) ' ' Source [MASK] . ▁That ▁saying ▁the ▁elect orial Sleeve ▁is [MASK] ▁e assy ▁to ▁mini p ulate . ▁' ' Faith less ' ' [MASK] ▁have ▁occasionally ▁refused [MASK] ▁vote ▁for ▁their ▁party [MASK] s ▁candidate ▁and ▁caste [MASK] ▁deciding ▁vote ▁for ▁whoever ▁they ▁pla ese . ▁What ▁that ▁just ▁means ▁is [MASK] ▁people ▁who [MASK] ▁for ▁that ▁pears on ▁might ▁as ▁well ▁just [MASK] ▁for ▁the [MASK] ▁side ▁if ▁the ▁electors ▁are ▁going ▁to ▁do ▁that . [MASK] \n",
      " \n",
      " [MASK] ▁In ▁Addition ▁what ▁if ▁a ▁state ▁sends ▁two ▁slate [MASK] ▁of ▁electors ▁to ▁Congress ▁again [MASK] ▁? ' ' [MASK] ▁Vice ▁President ▁Richard ▁Nixon , ▁who ▁was ▁presiding ▁over ▁the ▁Senate [MASK] [MASK] ▁only ▁his ▁opponent ' s ▁electors , ▁but buried ▁made [MASK] ▁guile ▁do ▁so ▁without ▁establishing ▁a ▁precedent ' ' Source [MASK] [MASK] ▁That [MASK] ▁very ▁well ▁happen ▁again , ▁by ▁mistake ▁the [MASK] [MASK] ▁could ▁send ▁two [MASK] s ▁to ▁congress [MASK] ▁than [MASK] ▁would ▁be ▁right ▁back ▁were ▁we ▁left ▁off . [end_evidence] \n",
      " \n",
      " [MASK] ▁In ▁Conclusion ▁the [MASK] orial ▁college ▁should ▁be ▁no ▁more ▁instead ▁of [MASK] [MASK] ▁should ▁be ▁able ▁to ▁vote ▁by [MASK] ▁voting ▁. ▁The ▁people ▁should ▁have ▁the ▁power ▁not [MASK] ▁people ▁vote ing ▁for [MASK] ▁to ▁maybe ▁or ▁maybe ▁not ▁have [MASK] ▁power ▁for ▁them [MASK] ▁. [SEP]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/Script/NLP/FPrize Effective Arguments/src/train_utils_mlm.py:474\u001b[0m, in \u001b[0;36mkfold\u001b[0;34m(args, df)\u001b[0m\n\u001b[1;32m    471\u001b[0m     train_df \u001b[38;5;241m=\u001b[39m df[df[args\u001b[38;5;241m.\u001b[39mkfold_name]\u001b[38;5;241m!=\u001b[39mi]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;66;03m#.sample(100)\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     valid_df \u001b[38;5;241m=\u001b[39m df[df[args\u001b[38;5;241m.\u001b[39mkfold_name]\u001b[38;5;241m==\u001b[39mi]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;66;03m#.sample(100)\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/Script/NLP/FPrize Effective Arguments/src/train_utils_mlm.py:385\u001b[0m, in \u001b[0;36mtrain_one_fold\u001b[0;34m(args, tokenizer, train_df, valid_df, fold)\u001b[0m\n\u001b[1;32m    382\u001b[0m n_parameters \u001b[38;5;241m=\u001b[39m count_parameters(model)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_parameters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trainable parameters\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 385\u001b[0m pred_val \u001b[38;5;241m=\u001b[39m \u001b[43mfit_net\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred_val\n",
      "File \u001b[0;32m~/Desktop/Kaggle/Script/NLP/FPrize Effective Arguments/src/train_utils_mlm.py:278\u001b[0m, in \u001b[0;36mfit_net\u001b[0;34m(model, train_dataset, val_dataset, args, fold)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 278\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    281\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adamw.py:137\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    135\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/_functional.py:139\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    137\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    141\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[1;32m    143\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold(args,train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
